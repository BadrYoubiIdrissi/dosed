{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dosed Training and Evaluation\n",
    "\n",
    "Requirements:\n",
    "\n",
    "1. You need the data for training as h5 files, to get them you either:\n",
    "  - Go through `download_and_data_format_explanation.ipynb`\n",
    "\n",
    "    or \n",
    "\n",
    "  - Run `make download_example`  you can use optionnal DOWNLOAD_PATH env variable to specify an alternative directory\n",
    "  \n",
    "2. Have dosed installed:\n",
    "    \n",
    "  - Run `pip install -e .` from dosed root directory\n",
    "  or \n",
    "  - Run `python setup.py develop` from dosed root directory\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "h5_directory = '../data/h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train, validation and test dataset creation\n",
    "\n",
    "## First we select which records we want to train, validate and test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tempfile\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "from dosed.utils import Compose\n",
    "from dosed.datasets import BalancedEventDataset as dataset\n",
    "from dosed.models import DOSED3 as model\n",
    "from dosed.datasets import get_train_validation_test\n",
    "from dosed.trainers import trainers\n",
    "from dosed.preprocessing import GaussianNoise, RescaleNormal, Invert\n",
    "\n",
    "seed = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records train: 11\n",
      "Number of records validation: 5\n",
      "Number of records test: 5\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = get_train_validation_test(h5_directory,\n",
    "                                                    percent_test=25,\n",
    "                                                    percent_validation=33,\n",
    "                                                    seed=seed)\n",
    "\n",
    "print(\"Number of records train:\", len(train))\n",
    "print(\"Number of records validation:\", len(validation))\n",
    "print(\"Number of records test:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we use the dataset class that will be use to generate sample for training and evaluation\n",
    "\n",
    "- h5_directory: Location of the generic h5 files.\n",
    "- signals: the signals from the h5 we want to include together with their normalization\n",
    "- events: the evvents from the h5 we want to train on\n",
    "- window: Spindles have a duration of ~1 seconds, so we design the samples accordingly by choosing 10 seconds windows\n",
    "- ratio_positive: sample within a training batch will have a probability of \"ratio_positive\" to contain at least one spindle \n",
    "- n_jobs: number of process used to extract and normalize signals from h5 files.\n",
    "- cache_data: cache results of extraction and normalization of signals from h5_file in h5_directory + \"/.cache\" (we strongly recommand to set True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10  # window duration in seconds\n",
    "ratio_positive = 0.5  # When creating the batch, sample containing at least one spindle will be drawn with that probability\n",
    "\n",
    "downsampling_rate = 2\n",
    "\n",
    "signals = [\n",
    "    {\n",
    "        'h5_path': '/eeg_0',\n",
    "        'processing': {\n",
    "            \"type\": \"clip_and_normalize\",\n",
    "            \"args\": {\n",
    "                    \"min_value\": -150,\n",
    "                \"max_value\": 150,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'h5_path': '/eeg_1',\n",
    "        'processing': {\n",
    "            \"type\": \"clip_and_normalize\",\n",
    "            \"args\": {\n",
    "                    \"min_value\": -150,\n",
    "                \"max_value\": 150,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "events = [\n",
    "    {\n",
    "        \"name\": \"spindle\",\n",
    "        \"h5_path\": \"spindle\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_parameters = {\n",
    "    \"h5_directory\": h5_directory,\n",
    "    \"signals\": signals,\n",
    "    \"events\": events,\n",
    "    \"window\": window,\n",
    "    \"downsampling_rate\": downsampling_rate,\n",
    "    \"ratio_positive\": ratio_positive,\n",
    "    \"n_jobs\": -1,  # Make use of parallel computing to extract and normalize signals from h5\n",
    "    \"cache_data\": True,  # by default will store normalized signals extracted from h5 in h5_directory + \"/.cache\" directory\n",
    "}\n",
    "\n",
    "dataset_validation = dataset(records=validation, **dataset_parameters)\n",
    "dataset_test = dataset(records=test, **dataset_parameters)\n",
    "\n",
    "# for training add data augmentation\n",
    "dataset_parameters_train = {\n",
    "    \"transformations\": Compose([\n",
    "        GaussianNoise(),\n",
    "        RescaleNormal(),\n",
    "        Invert(),\n",
    "    ])\n",
    "}\n",
    "dataset_parameters_train.update(dataset_parameters)\n",
    "dataset_train = dataset(records=train, **dataset_parameters_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a network\n",
    "\n",
    "The main parameters for the network are:\n",
    "  - default event sizes : to choose according to a priori size of the event to detect, here spindles are around 1 second\n",
    "  - k_max : number of CNN layers\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_event_sizes = [0.7, 1, 1.3]\n",
    "k_max = 5\n",
    "kernel_size = 5\n",
    "probability_dropout = 0.1\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input feature map size: 320\n",
      "Input receptive field: 0\n",
      "Input size in seconds: 10.0 s\n",
      "Input receptive field in seconds: 0.0 s \n",
      "\n",
      "After layer 1:\n",
      "\tFeature map size: 160\n",
      "\tReceptive field: 6\n",
      "\tReceptive field in seconds: 0.1875 s\n",
      "After layer 2:\n",
      "\tFeature map size: 80\n",
      "\tReceptive field: 16\n",
      "\tReceptive field in seconds: 0.5 s\n",
      "After layer 3:\n",
      "\tFeature map size: 40\n",
      "\tReceptive field: 36\n",
      "\tReceptive field in seconds: 1.125 s\n",
      "After layer 4:\n",
      "\tFeature map size: 20\n",
      "\tReceptive field: 76\n",
      "\tReceptive field in seconds: 2.375 s\n",
      "After layer 5:\n",
      "\tFeature map size: 10\n",
      "\tReceptive field: 156\n",
      "\tReceptive field in seconds: 4.875 s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_frequency = dataset_train.fs\n",
    "\n",
    "net_parameters = {\n",
    "    \"detection_parameters\": {\n",
    "        \"overlap_non_maximum_suppression\": 0.5,\n",
    "        \"classification_threshold\": 0.7\n",
    "    },\n",
    "    \"default_event_sizes\": [\n",
    "        default_event_size * sampling_frequency\n",
    "        for default_event_size in default_event_sizes\n",
    "    ],\n",
    "    \"k_max\": k_max,\n",
    "    \"kernel_size\": kernel_size,\n",
    "    \"pdrop\": probability_dropout,\n",
    "    \"fs\": sampling_frequency,   # just used to print architecture info with right time\n",
    "    \"input_shape\": dataset_train.input_shape,\n",
    "    \"number_of_classes\": dataset_train.number_of_classes,\n",
    "}\n",
    "net = model(**net_parameters)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the network\n",
    "\n",
    "Parameters are\n",
    "  - learning_rate\n",
    "  - loss type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_parameters = {\n",
    "    \"lr\": 5e-3,\n",
    "    \"weight_decay\": 1e-8,\n",
    "}\n",
    "loss_specs = {\n",
    "    \"type\": \"focal\",\n",
    "    \"parameters\": {\n",
    "        \"number_of_classes\": dataset_train.number_of_classes,\n",
    "        \"device\": device,\n",
    "    }\n",
    "}\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  0\n",
      "\u001b[32;1mLogging data to /tmp/tmp7fgllomw/train_history.json\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [02:37<49:49, 157.33s/it, best_metric_score=0.0258, last_update=0, threshold=0.634]"
     ]
    }
   ],
   "source": [
    "trainer = trainers[\"adam\"](\n",
    "    net,\n",
    "    optimizer_parameters=optimizer_parameters,\n",
    "    loss_specs=loss_specs,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "best_net_train, best_metrics_train, best_threshold_train = trainer.train(\n",
    "    dataset_train,\n",
    "    dataset_validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_net_train.predict_dataset(\n",
    "    dataset_test,\n",
    "    best_threshold_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "record = dataset_test.records[1]\n",
    "\n",
    "index_spindle = 29\n",
    "window_duration = 5\n",
    "\n",
    "# retrive spindle at the right index\n",
    "spindle_start = float(predictions[record][0][index_spindle][0]) / sampling_frequency\n",
    "spindle_end = float(predictions[record][0][index_spindle][1]) / sampling_frequency\n",
    "\n",
    "# center data window on annotated spindle \n",
    "start_window = spindle_start + (spindle_end - spindle_start) / 2 - window_duration\n",
    "stop_window = spindle_start + (spindle_end - spindle_start) / 2 + window_duration\n",
    "\n",
    "# Retrieve EEG data at right index\n",
    "index_start = int(start_window * sampling_frequency)\n",
    "index_stop = int(stop_window * sampling_frequency)\n",
    "y = dataset_test.signals[record][\"data\"][0][index_start:index_stop]\n",
    "\n",
    "# Build corresponding time support\n",
    "t = start_window + np.cumsum(np.ones(index_stop - index_start) * 1 / sampling_frequency)\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(t, y)\n",
    "plt.axvline(spindle_end)\n",
    "plt.axvline(spindle_start)\n",
    "plt.ylim([-1, 1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
