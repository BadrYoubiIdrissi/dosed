{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dosed Training and Evaluation\n",
    "\n",
    "You need the data for training as memmaps, to get them you either:\n",
    "  - Go through `download_and_data_format_explanation.ipynb`\n",
    "\n",
    "or \n",
    "\n",
    "  - Run `bash ./minimum_example/download_and_format_data.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from settings import MINIMUM_EXAMPLE_SETTINGS as settings\n",
    "import os\n",
    "import json\n",
    "\n",
    "h5_directory = settings[\"h5_directory\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train, validation and test dataset creation\n",
    "\n",
    "## First we select which records we want to train, validate and test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tempfile\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "from dosed.preprocessings import RescaleNormal, Invert, GaussianNoise\n",
    "from dosed.utils import Compose\n",
    "from dosed.datasets import BalancedEventDataset as dataset\n",
    "from dosed.models import DOSED3 as model\n",
    "from dosed.datasets import get_train_validation_test\n",
    "from dosed.trainers import trainers\n",
    "\n",
    "seed = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records train: 11\n",
      "Number of records validation: 5\n",
      "Number of records test: 5\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = get_train_validation_test(h5_directory,\n",
    "                                                    percent_test=25,\n",
    "                                                    percent_validation=33,\n",
    "                                                    seed_validation=seed,\n",
    "                                                    seed_test=seed)\n",
    "\n",
    "print(\"Number of records train:\", len(train))\n",
    "print(\"Number of records validation:\", len(validation))\n",
    "print(\"Number of records test:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we use the dataset class that will be use to generate sample for training and evaluation\n",
    "\n",
    "- window: Spindles have a duration of ~1 seconds, so we design the samples accordingly by choosing 10 seconds windows\n",
    "- ratio_positive: sample within a training batch will have a probability of \"ratio_positive\" to contain at least one spindle \n",
    "- signals: the signals from the h5 we want to include together with their preprocessing\n",
    "- events: the evvents from the h5 we want to train on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10  # window duration in seconds\n",
    "ratio_positive = 0.5  # When creating the batch, sample containing at least one spindle will be drawn with that probability\n",
    "\n",
    "downsampling_rate = 2\n",
    "\n",
    "signals = [\n",
    "    {\n",
    "        'h5_path': '/eeg_0',\n",
    "        'processing': {\n",
    "            \"type\": \"clip_and_normalize\",\n",
    "            \"args\": {\n",
    "                    \"min_value\": -150,\n",
    "                \"max_value\": 150,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'h5_path': '/eeg_1',\n",
    "        'processing': {\n",
    "            \"type\": \"clip_and_normalize\",\n",
    "            \"args\": {\n",
    "                    \"min_value\": -150,\n",
    "                \"max_value\": 150,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "events = [\n",
    "    {\n",
    "        \"name\": \"spindle\",\n",
    "        \"h5_path\": \"spindle\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_parameters = {\n",
    "    \"h5_directory\": h5_directory,\n",
    "    \"signals\": signals,\n",
    "    \"events\": events,\n",
    "    \"window\": window,\n",
    "    \"downsampling_rate\": downsampling_rate,\n",
    "    \"ratio_positive\": ratio_positive,\n",
    "}\n",
    "\n",
    "dataset_validation = dataset(records=validation, **dataset_parameters)\n",
    "dataset_test = dataset(records=test, **dataset_parameters)\n",
    "\n",
    "# for training add data augmentation\n",
    "dataset_parameters_train = {\n",
    "    \"transformations\": Compose([\n",
    "        GaussianNoise(),\n",
    "        RescaleNormal(),\n",
    "        Invert(),\n",
    "    ])\n",
    "}\n",
    "dataset_parameters_train.update(dataset_parameters)\n",
    "dataset_train = dataset(records=train, **dataset_parameters_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a network\n",
    "\n",
    "The main parameters for the network are:\n",
    "  - default event sizes : to choose according to a priori size of the event to detect, here spindles are around 1 second\n",
    "  - k_max : number of CNN layers\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_event_sizes = [0.7, 1, 1.3]\n",
    "k_max = 5\n",
    "kernel_size = 5\n",
    "probability_dropout = 0.1\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input feature map size: 320\n",
      "Input receptive field: 0\n",
      "Input size in seconds: 10.0 s\n",
      "Input receptive field in seconds: 0.0 s \n",
      "\n",
      "After layer 1:\n",
      "\tFeature map size: 160\n",
      "\tReceptive field: 6\n",
      "\tReceptive field in seconds: 0.1875 s\n",
      "After layer 2:\n",
      "\tFeature map size: 80\n",
      "\tReceptive field: 16\n",
      "\tReceptive field in seconds: 0.5 s\n",
      "After layer 3:\n",
      "\tFeature map size: 40\n",
      "\tReceptive field: 36\n",
      "\tReceptive field in seconds: 1.125 s\n",
      "After layer 4:\n",
      "\tFeature map size: 20\n",
      "\tReceptive field: 76\n",
      "\tReceptive field in seconds: 2.375 s\n",
      "After layer 5:\n",
      "\tFeature map size: 10\n",
      "\tReceptive field: 156\n",
      "\tReceptive field in seconds: 4.875 s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_frequency = dataset_train.fs\n",
    "\n",
    "net_parameters = {\n",
    "    \"detection_parameters\": {\n",
    "        \"overlap_non_maximum_suppression\": 0.5,\n",
    "        \"classification_threshold\": 0.7\n",
    "    },\n",
    "    \"default_event_sizes\": [\n",
    "        default_event_size * sampling_frequency\n",
    "        for default_event_size in default_event_sizes\n",
    "    ],\n",
    "    \"k_max\": k_max,\n",
    "    \"kernel_size\": kernel_size,\n",
    "    \"pdrop\": probability_dropout,\n",
    "    \"fs\": sampling_frequency,   # just used to print architecture info with right time\n",
    "    \"input_shape\": dataset_train.input_shape,\n",
    "    \"number_of_classes\": dataset_train.number_of_classes,\n",
    "}\n",
    "net = model(**net_parameters)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the network\n",
    "\n",
    "Parameters are\n",
    "  - learning_rate\n",
    "  - loss type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_parameters = {\n",
    "    \"lr\": 5e-3,\n",
    "    \"weight_decay\": 1e-8,\n",
    "}\n",
    "loss_specs = {\n",
    "    \"type\": \"focal\",\n",
    "    \"parameters\": {\n",
    "        \"number_of_classes\": dataset_train.number_of_classes,\n",
    "        \"device\": device,\n",
    "    }\n",
    "}\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  0\n",
      "\u001b[32;1mLogging data to /tmp/tmpbe06tl89/train_history.json\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [09:44<29:34, 118.31s/it, best_metric_score=0.294, last_update=4, threshold=0.622]"
     ]
    }
   ],
   "source": [
    "trainer = trainers[\"adam\"](\n",
    "    net,\n",
    "    optimizer_parameters=optimizer_parameters,\n",
    "    loss_specs=loss_specs,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "best_net_train, best_metrics_train, best_threshold_train = trainer.train(\n",
    "    dataset_train,\n",
    "    dataset_validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_net_train.predict_dataset(\n",
    "    dataset_test,\n",
    "    best_threshold_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "record = dataset_test.records[1]\n",
    "\n",
    "index_spindle = 29\n",
    "window_duration = 5\n",
    "\n",
    "# retrive spindle at the right index\n",
    "spindle_start = float(predictions[record][0][index_spindle][0]) / sampling_frequency\n",
    "spindle_end = float(predictions[record][0][index_spindle][1]) / sampling_frequency\n",
    "\n",
    "# center data window on annotated spindle \n",
    "start_window = spindle_start + (spindle_end - spindle_start) / 2 - window_duration\n",
    "stop_window = spindle_start + (spindle_end - spindle_start) / 2 + window_duration\n",
    "\n",
    "# Retrieve EEG data at right index\n",
    "index_start = int(start_window * sampling_frequency)\n",
    "index_stop = int(stop_window * sampling_frequency)\n",
    "y = dataset_test.signals[record][\"data\"][0][index_start:index_stop]\n",
    "\n",
    "# Build corresponding time support\n",
    "t = start_window + np.cumsum(np.ones(index_stop - index_start) * 1 / sampling_frequency)\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(t, y)\n",
    "plt.axvline(spindle_end)\n",
    "plt.axvline(spindle_start)\n",
    "plt.ylim([-1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
